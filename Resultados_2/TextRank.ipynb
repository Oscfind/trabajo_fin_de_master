{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\oscarandres.pinilla\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]     ...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\oscarandres.pinilla\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]     ...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "c:\\Users\\oscarandres.pinilla\\anaconda3\\envs\\tfm\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\oscarandres.pinilla\\anaconda3\\envs\\tfm\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\oscarandres.pinilla\\anaconda3\\envs\\tfm\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           BLEU\n",
      "0  0.0007277250\n",
      "1  0.0000000000\n",
      "2  0.0141682980\n",
      "3  0.0042923562\n",
      "4  0.0000091974\n",
      "5  0.0015113701\n",
      "6  0.0000000000\n",
      "7  0.0012691017\n",
      "8  0.0000000000\n",
      "9  0.0125157877\n",
      "10 0.0000000000\n",
      "11 0.0070182728\n",
      "12 0.0000000000\n",
      "13 0.0000001804\n",
      "14 0.0019937322\n",
      "15 0.0000000000\n",
      "16 0.0000000000\n",
      "17 0.0480140617\n",
      "18 0.0000000000\n",
      "19 0.0000000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Carga del dataset\n",
    "df_ref = pd.read_csv(\"df_ref.csv\")\n",
    "\n",
    "bleu_scores = []\n",
    "\n",
    "def generate_summary(article, num_sentences):\n",
    "    sentences = sent_tokenize(article)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = [word_tokenize(sentence) for sentence in sentences]\n",
    "    filtered_sentences = [' '.join([word for word in words if word.lower() not in stop_words]) for words in word_tokens]\n",
    "\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(filtered_sentences)\n",
    "\n",
    "    similarity_matrix = X.dot(X.T)\n",
    "\n",
    "    scores = similarity_matrix.sum(axis=0)\n",
    "    top_sentence_indices = sorted(range(len(scores)), key=lambda i: scores[i])[-num_sentences:]\n",
    "    \n",
    "    summary = ' '.join([sentences[i] for i in top_sentence_indices])\n",
    "    \n",
    "    return summary\n",
    "\n",
    "for index, row in df_ref.iterrows():\n",
    "    article = row['article']\n",
    "    original_summary = row['abstract']\n",
    "    \n",
    "    generated_summary = generate_summary(article, num_sentences=3) \n",
    "    \n",
    "    hypothesis_tokens = word_tokenize(generated_summary)\n",
    "    reference_tokens = word_tokenize(original_summary)\n",
    "    \n",
    "    bleu = sentence_bleu([reference_tokens], hypothesis_tokens)\n",
    "    \n",
    "    bleu_scores.append(bleu)\n",
    "\n",
    "bleu_scores_df = pd.DataFrame({\n",
    "    'BLEU': bleu_scores\n",
    "})\n",
    "\n",
    "pd.options.display.float_format = '{:.10f}'.format\n",
    "\n",
    "print(bleu_scores_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BLEU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0007277250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0141682980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0042923562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0000091974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0015113701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0012691017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0125157877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0070182728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0000001804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0019937322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0480140617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           BLEU\n",
       "0  0.0007277250\n",
       "1  0.0000000000\n",
       "2  0.0141682980\n",
       "3  0.0042923562\n",
       "4  0.0000091974\n",
       "5  0.0015113701\n",
       "6  0.0000000000\n",
       "7  0.0012691017\n",
       "8  0.0000000000\n",
       "9  0.0125157877\n",
       "10 0.0000000000\n",
       "11 0.0070182728\n",
       "12 0.0000000000\n",
       "13 0.0000001804\n",
       "14 0.0019937322\n",
       "15 0.0000000000\n",
       "16 0.0000000000\n",
       "17 0.0480140617\n",
       "18 0.0000000000\n",
       "19 0.0000000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para posteriores cálculos se extrae el dataframe \n",
    "bleu_scores_df.to_csv('BLEU_scores_TextRank_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oscarandres.pinilla\\AppData\\Local\\Temp\\ipykernel_12820\\577242402.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\oscarandres.pinilla\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]     ...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           BLEU\n",
      "0  0.0748935423\n",
      "1  0.1529597873\n",
      "2  0.0346570319\n",
      "3  0.0156254953\n",
      "4  0.0234341730\n",
      "5  0.0266479114\n",
      "6  0.0796730365\n",
      "7  0.1386817566\n",
      "8  0.2168152423\n",
      "9  0.0784953590\n",
      "10 0.0510081553\n",
      "11 0.0522166009\n",
      "12 0.0450548765\n",
      "13 0.1517918626\n",
      "14 0.1260095406\n",
      "15 0.1015122026\n",
      "16 0.0158863685\n",
      "17 0.0379230741\n",
      "18 0.0562689669\n",
      "19 0.0505752050\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from summa import summarizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Carga del dataset\n",
    "df_ref = pd.read_csv(\"df_ref.csv\")\n",
    "\n",
    "bleu_scores = []\n",
    "\n",
    "for index, row in df_ref.iterrows():\n",
    "    article = row['article']\n",
    "    original_summary = row['abstract']\n",
    "    \n",
    "    # Genera el resumen usando TextRank\n",
    "    generated_summary = summarizer.summarize(article, ratio=0.2)  # Puedes ajustar la proporción según lo desees\n",
    "    \n",
    "    # Tokenización del resumen generado y del resumen original\n",
    "    hypothesis_tokens = word_tokenize(generated_summary)\n",
    "    reference_tokens = word_tokenize(original_summary)\n",
    "    \n",
    "    # Cálculo de BLEU Score\n",
    "    bleu = sentence_bleu([reference_tokens], hypothesis_tokens)\n",
    "    \n",
    "    bleu_scores.append(bleu)\n",
    "\n",
    "bleu_scores_df = pd.DataFrame({\n",
    "    'BLEU': bleu_scores\n",
    "})\n",
    "\n",
    "pd.options.display.float_format = '{:.10f}'.format\n",
    "\n",
    "print(bleu_scores_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BLEU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0748935423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1529597873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0346570319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0156254953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0234341730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0266479114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0796730365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1386817566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2168152423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0784953590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0510081553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0522166009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0450548765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.1517918626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.1260095406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.1015122026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0158863685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0379230741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0562689669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0505752050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           BLEU\n",
       "0  0.0748935423\n",
       "1  0.1529597873\n",
       "2  0.0346570319\n",
       "3  0.0156254953\n",
       "4  0.0234341730\n",
       "5  0.0266479114\n",
       "6  0.0796730365\n",
       "7  0.1386817566\n",
       "8  0.2168152423\n",
       "9  0.0784953590\n",
       "10 0.0510081553\n",
       "11 0.0522166009\n",
       "12 0.0450548765\n",
       "13 0.1517918626\n",
       "14 0.1260095406\n",
       "15 0.1015122026\n",
       "16 0.0158863685\n",
       "17 0.0379230741\n",
       "18 0.0562689669\n",
       "19 0.0505752050"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para posteriores cálculos se extrae el dataframe \n",
    "bleu_scores_df.to_csv('BLEU_scores_TextRank_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
