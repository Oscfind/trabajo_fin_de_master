{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oscarandres.pinilla\\AppData\\Local\\Temp\\ipykernel_21356\\2781410315.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "c:\\Users\\oscarandres.pinilla\\anaconda3\\envs\\tfm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\oscarandres.pinilla\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]     ...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "c:\\Users\\oscarandres.pinilla\\anaconda3\\envs\\tfm\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\oscarandres.pinilla\\anaconda3\\envs\\tfm\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\oscarandres.pinilla\\anaconda3\\envs\\tfm\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           BLEU\n",
      "0  0.0019906194\n",
      "1  0.0000000000\n",
      "2  0.0584887993\n",
      "3  0.1207528166\n",
      "4  0.0007681192\n",
      "5  0.0179435640\n",
      "6  0.0000000000\n",
      "7  0.0012691017\n",
      "8  0.0173535382\n",
      "9  0.0329923109\n",
      "10 0.0000000000\n",
      "11 0.0822033535\n",
      "12 0.0000000000\n",
      "13 0.0002401373\n",
      "14 0.1013743580\n",
      "15 0.0000000000\n",
      "16 0.0000000000\n",
      "17 0.0574372412\n",
      "18 0.0000000000\n",
      "19 0.0000000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Carga del dataset\n",
    "df_ref = pd.read_csv(\"df_ref.csv\")\n",
    "\n",
    "model_name = 't5-small'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "bleu_scores = []\n",
    "\n",
    "def generate_summary_t5(article, reference_summary):\n",
    "    input_text = \"summarize: \" + article\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    \n",
    "    summary_ids = model.generate(input_ids, max_length=150, num_beams=4, early_stopping=True)\n",
    "    generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    reference_tokens = nltk.word_tokenize(reference_summary)\n",
    "    hypothesis_tokens = nltk.word_tokenize(generated_summary)\n",
    "    bleu = sentence_bleu([reference_tokens], hypothesis_tokens)\n",
    "    \n",
    "    return generated_summary, bleu\n",
    "e\n",
    "for index, row in df_ref.iterrows():\n",
    "    article = row['article']\n",
    "    reference_summary = row['abstract']\n",
    "    \n",
    "    generated_summary, bleu = generate_summary_t5(article, reference_summary)\n",
    "    \n",
    "    bleu_scores.append(bleu)\n",
    "\n",
    "bleu_scores_df = pd.DataFrame({\n",
    "    'BLEU': bleu_scores\n",
    "})\n",
    "\n",
    "pd.options.display.float_format = '{:.10f}'.format\n",
    "\n",
    "print(bleu_scores_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BLEU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0019906194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0584887993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1207528166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0007681192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0179435640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0012691017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0173535382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0329923109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0822033535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0002401373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.1013743580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0574372412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           BLEU\n",
       "0  0.0019906194\n",
       "1  0.0000000000\n",
       "2  0.0584887993\n",
       "3  0.1207528166\n",
       "4  0.0007681192\n",
       "5  0.0179435640\n",
       "6  0.0000000000\n",
       "7  0.0012691017\n",
       "8  0.0173535382\n",
       "9  0.0329923109\n",
       "10 0.0000000000\n",
       "11 0.0822033535\n",
       "12 0.0000000000\n",
       "13 0.0002401373\n",
       "14 0.1013743580\n",
       "15 0.0000000000\n",
       "16 0.0000000000\n",
       "17 0.0574372412\n",
       "18 0.0000000000\n",
       "19 0.0000000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para posteriores c√°lculos se extrae el dataframe \n",
    "bleu_scores_df.to_csv('BLEU_scores_T5_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
